{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editing Model Demo\n",
    "\n",
    "This notebook is a demonstration of how to use the T5 transformer model to automate the language editing process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "A high quality dataseet of unedited and edited sentence pairs is required to train this model. Unfortunately no such dataset is freely available. As an alternative, this notebook demonstrates the process using an artificially constructed dataset that is designed to meet these requirements. A range of errors will be introduced to sentences from an NLTK corpus; in this case, the original sentence is equivalent to the edited sentence, and the sentence with introduced errors is equivalent to the unedited sentence. \n",
    "\n",
    "For demonstration purposes, three simple errors will be applied to the sentences: 1) plural nouns will be randomly singularized and singular nouns will be randomly pluralized; 2) indefinite articles (a/an) will be randomly switched; and 3) commas and semicolons will be randomly switched. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "nltk.download('brown')\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plural_error(tagged_sent, p):\n",
    "    \"\"\"\n",
    "    Introduce plural errors to nouns in tagged_sent with \n",
    "    probability p; tagged_sent is a list of pairs where the first\n",
    "    pair item is the word and the second pair item is the tag\n",
    "    \"\"\"\n",
    "    upper_prob_limit = int(1/p) - 1\n",
    "    for i, (word, tag) in enumerate(tagged_sent):\n",
    "        if tag == \"NNS\" and random.randint(0, upper_prob_limit) == 0:\n",
    "            if word[-3:] == \"ies\":\n",
    "                tagged_sent[i] = (word[:-3] + \"y\", tag)\n",
    "            else:\n",
    "                tagged_sent[i] = (word[:-1], tag)\n",
    "        if tag == \"NN\" and random.randint(0, upper_prob_limit) == 0:\n",
    "            if word[-1] == \"y\":\n",
    "                tagged_sent[i] = (word[:-1] + \"ies\", tag)\n",
    "            else:\n",
    "                tagged_sent[i] = (word + \"s\", tag)\n",
    "    return tagged_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In college library , 57 per cents of the totals numbers of book are owned by 124 of 1,509 institutions surveyed last years by the U.S. Office of Education.\n"
     ]
    }
   ],
   "source": [
    "sent = brown.tagged_sents(categories=['news'])[4618]\n",
    "sent = plural_error(sent, 0.5)\n",
    "print(TreebankWordDetokenizer().detokenize([w for w, t in sent]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indefinite_article_error(tagged_sent, p):\n",
    "    \"\"\"\n",
    "    Introduce indefinite article errors (a/an) to tagged_sent with \n",
    "    probability p; tagged_sent is a list of pairs where the first\n",
    "    pair item is the word and the second pair item is the tag\n",
    "    \"\"\"\n",
    "    upper_prob_limit = int(1/p) - 1\n",
    "    for i, (word, tag) in enumerate(tagged_sent):\n",
    "        if word == \"a\" and random.randint(0, upper_prob_limit) == 0:\n",
    "            tagged_sent[i] = (\"an\", tag)\n",
    "        if word == \"an\" and random.randint(0, upper_prob_limit) == 0:\n",
    "            tagged_sent[i] = (\"a\", tag)\n",
    "    return tagged_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- President Kennedy today proposed an mammoth new medical cares program whereby social security taxes on 70 million American worker would be raised to pay the hospital and some other medical bills of 14.2 million Americans over 65 who are covered by social security or railroad retirements program.\n"
     ]
    }
   ],
   "source": [
    "sent = brown.tagged_sents(categories=['news'])[237]\n",
    "sent = plural_error(sent, 0.5)\n",
    "sent = indefinite_article_error(sent, 0.5)\n",
    "print(TreebankWordDetokenizer().detokenize([w for w, t in sent]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semicolon_error(tagged_sent, p):\n",
    "    \"\"\"\n",
    "    Introduce semicolon errors (;/,) to tagged_sent with \n",
    "    probability p; tagged_sent is a list of pairs where the first\n",
    "    pair item is the word and the second pair item is the tag\n",
    "    \"\"\"\n",
    "    upper_prob_limit = int(1/p) - 1\n",
    "    for i, (word, tag) in enumerate(tagged_sent):\n",
    "        if word == \",\" and random.randint(0, upper_prob_limit) == 0:\n",
    "            tagged_sent[i] = (\";\", tag)\n",
    "        if word == \";\" and random.randint(0, upper_prob_limit) == 0:\n",
    "            tagged_sent[i] = (\",\", tag)\n",
    "    return tagged_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under committee rule; it went automatically to a subcommittees for one week.\n"
     ]
    }
   ],
   "source": [
    "sent = brown.tagged_sents(categories=['news'])[101]\n",
    "sent = plural_error(sent, 0.5)\n",
    "sent = indefinite_article_error(sent, 0.5)\n",
    "sent = semicolon_error(sent, 0.5)\n",
    "print(TreebankWordDetokenizer().detokenize([w for w, t in sent]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_sents = [TreebankWordDetokenizer().detokenize(sent) for sent in brown.sents(categories=['news'])]\n",
    "\n",
    "error_tagged_sents = [semicolon_error(indefinite_article_error(plural_error(sent, 0.5), 0.5), 0.5) \n",
    "                      for sent in brown.tagged_sents(categories=['news'])]\n",
    "unedited_sents = [TreebankWordDetokenizer().detokenize([w for w, t in error_tagged_sent]) \n",
    "                  for error_tagged_sent in error_tagged_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unedited</th>\n",
       "      <th>edited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Fulton County Grand Jury said Friday an in...</td>\n",
       "      <td>The Fulton County Grand Jury said Friday an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The jury further said in term-ends presentment...</td>\n",
       "      <td>The jury further said in term-end presentments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The September-October terms juries had been ch...</td>\n",
       "      <td>The September-October term jury had been charg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\\" Only an relative handful of such report was...</td>\n",
       "      <td>\\\" Only a relative handful of such reports was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The juries said it did find that many of Georg...</td>\n",
       "      <td>The jury said it did find that many of Georgia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>In college library , 57 per cent of the total ...</td>\n",
       "      <td>In college libraries , 57 per cent of the tota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>And over 66 per cent of the elementary schools...</td>\n",
       "      <td>And over 66 per cent of the elementary schools...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620</th>\n",
       "      <td>In every aspect of services--to the public, to...</td>\n",
       "      <td>In every aspect of service--to the public, to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4621</th>\n",
       "      <td>Only public understandings and supports can pr...</td>\n",
       "      <td>Only public understanding and support can prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4622</th>\n",
       "      <td>This is one of the main reason for National Li...</td>\n",
       "      <td>This is one of the main reasons for National L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4623 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               unedited  \\\n",
       "0     The Fulton County Grand Jury said Friday an in...   \n",
       "1     The jury further said in term-ends presentment...   \n",
       "2     The September-October terms juries had been ch...   \n",
       "3     \\\" Only an relative handful of such report was...   \n",
       "4     The juries said it did find that many of Georg...   \n",
       "...                                                 ...   \n",
       "4618  In college library , 57 per cent of the total ...   \n",
       "4619  And over 66 per cent of the elementary schools...   \n",
       "4620  In every aspect of services--to the public, to...   \n",
       "4621  Only public understandings and supports can pr...   \n",
       "4622  This is one of the main reason for National Li...   \n",
       "\n",
       "                                                 edited  \n",
       "0     The Fulton County Grand Jury said Friday an in...  \n",
       "1     The jury further said in term-end presentments...  \n",
       "2     The September-October term jury had been charg...  \n",
       "3     \\\" Only a relative handful of such reports was...  \n",
       "4     The jury said it did find that many of Georgia...  \n",
       "...                                                 ...  \n",
       "4618  In college libraries , 57 per cent of the tota...  \n",
       "4619  And over 66 per cent of the elementary schools...  \n",
       "4620  In every aspect of service--to the public, to ...  \n",
       "4621  Only public understanding and support can prov...  \n",
       "4622  This is one of the main reasons for National L...  \n",
       "\n",
       "[4623 rows x 2 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"unedited\": unedited_sents, \"edited\": edited_sents})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset\", \"wb\") as file:\n",
    "    pickle.dump(df, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset\", \"rb\") as file:\n",
    "    df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove entries without editing changes\n",
    "df = df[~(df.unedited == df.edited)]\n",
    "\n",
    "# Add the \"edit\" instruction to the input sentences for the T5 model\n",
    "df.unedited = pd.Series([\"edit: \"] * df.shape[0]) + df.unedited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EditDataset(Dataset):\n",
    "    def __init__(self, unedited_sentences, edited_sentences):\n",
    "        self.unedited_sentences = unedited_sentences\n",
    "        self.edited_sentences = edited_sentences\n",
    "         \n",
    "    def __len__(self):\n",
    "        return (len(self.unedited_sentences))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return (self.unedited_sentences[i], self.edited_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data = EditDataset(df_train.unedited.values, df_train.edited.values)\n",
    "val_data = EditDataset(df_val.unedited.values, df_val.edited.values)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "valloader = DataLoader(val_data, batch_size=8, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
